---
layout: default
---
# **Jaehoon Lee**

<img align="right" style="float:center;padding:10px;" width="250" src="/image/IMG_2635.JPG">

Google Brain  
1600 Amphitheatre Parkway  
attn: jaehlee  
Mountain View, CA, 94043  

**E-Mail** eejaehooon at gmail dot com



I am a [AI Resident](https://ai.google/research/join-us/ai-residency) at [Google Brain Team](https://research.google.com/teams/brain/) interested in understanding deep neural networks. 

Before joining Google in 2017, I mostly worked on theoretical physics. 
I was a postdoctoral researcher in the [Department of Physics & Astronomy](http://www.phas.ubc.ca/) at [University of British Columbia (UBC)](http://www.ubc.ca/) in the String Theory Group. 
Before that, I completed my PhD in [Center for Theoretical Physics (CTP)](http://ctp.lns.mit.edu/) at [MIT](http://web.mit.edu/) working on theoretical physics. 

My research interest is in theoretical physics and machine learning (deep neural networks in particular). Some details of my research is listed [here](/research/).

## News

* Feb 2019: Our new paper [Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent
](https://arxiv.org/abs/1902.06720) is out on ArXiv!  

* Feb 2019: Website is updated!

## Publication

[[Google Scholar]](https://scholar.google.com/citations?user=d3YhiooAAAAJ&hl=en) [[arXiv]](https://arxiv.org/a/lee_j_7.html)  

* **Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent**  
Jaehoon Lee*, Lechao Xiao*, Samuel S. Schoenholz, Yasaman Bahri, Jascha Sohl-Dickstein, Jeffrey Pennington  
[[arXiv: 1902.06720]](https://arxiv.org/abs/1902.06720)


* **Measuring the Effects of Data Parallelism on Neural Network Training**  
Christopher J. Shallue*, Jaehoon Lee*, Joseph Antognini, Jascha Sohl-Dickstein, Roy Frostig, George E. Dahl  
[[arXiv: 1811.03600]](https://arxiv.org/abs/1811.03600)


* **Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes**  
Roman Novak*, Lechao Xiao*, Jaehoon Lee&, Yasaman Bahri&, Greg Yang, Daniel A. Abolafia, Jeffrey Pennington, Jascha Sohl-Dickstein  
International Conference on Learning Representations (ICLR), 2019.  
[[arXiv: 1810.05148]](https://arxiv.org/abs/1810.05148)


* **Deep Neural Networks as Gaussian Processes**  
Jaehoon Lee*, Yasaman Bahri*, Roman Novak, Samuel S. Schoenholz, Jeffrey Pennington, Jascha Sohl-Dickstein  
International Conference on Learning Representations (ICLR), 2018.
[[arXiv: 1711.00165]](https://arxiv.org/abs/1711.00165) [[code]](https://github.com/brain-research/nngp)

* **3d N=2 minimal SCFTs from Wrapped M5-branes**
Jin-Beom Bae*, Dongmin Gang*, Jaehoon Lee*
Journal of High Energy Physics (JHEP), 2017.
[[arXiv: 1610.09259]](https://arxiv.org/abs/1610.09259)

## Research

* Recent research interests include:
  1. Interplay between physics and machine learning
  2. Theoretical aspects of deep neural networks
  3. Theoretical Physics with focus on high energy physics
  

* Services:
  1. Reviewer for ICLR / ICML / NeurIPS
  2. Organizer for [Aspen Winter Conference on Physics for Machine Learning](https://sites.google.com/corp/view/phys4ml/)
  3. Organizer for Vancouver deep learning study group
